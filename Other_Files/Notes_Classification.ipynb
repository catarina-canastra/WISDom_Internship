{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries and packages (dependencies)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Machine learning models for Classification:\n",
    "# To implement kNN Classifier model, use scikit-learn and import KNeighborsClassifier from sklearn.neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# To implement Extra Trees Classifier model, use scikit-learn and import ExtraTreesClassifier from sklearn.ensemble\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "# To implement Gaussian Bayes Classifier model, use scikit-learn and import GaussianNB from sklearn.naive_bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# To implement three SVM Kernel's, use scikit-learn and import SVC from sklearn.svm\n",
    "from sklearn.svm import SVC\n",
    "# Validation results of the developed machine learning models\n",
    "#(validation measurements, confusion matrices, decision limits in image format)\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "# from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class balance\n",
    "class_dist=barreiro_ano.groupby('detection').size()\n",
    "class_label=pd.DataFrame(barreiro_ano,columns=['count'])\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.barplot(x=class_label.index,y='count',data=class_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# But it is interesting the percentwise distribution of each class\n",
    "for i,number in enumerate(class_dist):\n",
    "    percent=(number/class_dist.sum())*100\n",
    "    print('Detection',class_dist.index[i])\n",
    "    print('%.2f'% percent,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_data=barreiro_ano['value']\n",
    "\n",
    "for i, col in enumerate(cont_data.columns):\n",
    "    plt.figure(i)\n",
    "    sns.distplot(cont_data[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The above plots more or less tells about the skewness that I saw earlier.\n",
    "# Let's dig down into Bivariate and Multivariate Analysis.\n",
    "# Let's check for distribution with respect to our target.\n",
    "# Here, First i want to check the shape of continous features with respect to the target class.\n",
    "# Hence I'll use the continuous_data (cont_data) and plot a boxplot against target.\n",
    "# I can also look at violinplot here, It's visually appealing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barreiro_ano['detection']=barreiro_ano['detection'].astype('category')\n",
    "#To convert target class into category\n",
    "\n",
    "for i, col in enumerate(cont_data.columns):\n",
    "    plt.figure(i,figsize=(8,4))\n",
    "    sns.boxplot(x=barreiro_ano['detection'], y=col, data=barreiro_ano, palette=\"coolwarm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "sns.heatmap(cont_data.corr(),cmap='magma',linecolor='white',linewidths=1,annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.PairGrid(cont_data)\n",
    "g.map(plt.scatter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This gives us the relation and its shape with respect to other features.\n",
    "# Various inferences can be drwan out.\n",
    "# Pairgrid plot is just awesome. And it's even more awesome when it's combined with KDE clusters.\n",
    "# But for considerably heavy data, its time consuming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = Input or independent variables\n",
    "# y= Target (dependent) variable ('Cover_Type (7 types)')\n",
    "X=covtype.loc[:,'date':'value']\n",
    "y=covtype['detection']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data into  train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the classes as integers, we use the LabelEncoder class from scikit-learn\n",
    "le = LabelEncoder() y = le.fit_transform(dados['Cover_Type (7 types)'])\n",
    "# This methodology was not implemented (used)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Setup arrays to store training and test accuracies\n",
    "neighbors = np.arange(1,7)\n",
    "train_accuracy =np.empty(len(neighbors))\n",
    "test_accuracy = np.empty(len(neighbors))\n",
    "\n",
    "for i,k in enumerate(neighbors):\n",
    "    # Setup a knn classifier with k neighbors\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    \n",
    "    # Fit the model\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    # Compute accuracy on the training set\n",
    "    train_accuracy[i] = knn.score(X_train, y_train)\n",
    "    \n",
    "    # Compute accuracy on the test set\n",
    "    test_accuracy[i] = knn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's visualize the change in accuracies with respect to train and test data at different neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate plot\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.title('k-NN Varying number of neighbors')\n",
    "plt.plot(neighbors, test_accuracy, label='Testing Accuracy')\n",
    "plt.plot(neighbors, train_accuracy, label='Training accuracy')\n",
    "plt.legend()\n",
    "plt.xlabel('Number of neighbors')\n",
    "plt.ylabel('Accuracy')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neighbor value = 5 yeilds the best result. Let's go by that for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup a knn classifier with k neighbors\n",
    "knn = KNeighborsClassifier(n_neighbors=5) #Using Eucledian distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "knn.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get accuracy. Note: In case of classification algorithms score method represents accuracy.\n",
    "accuracy_knn=knn.score(X_test,y_test)\n",
    "print('KNN Accuracy: ',accuracy_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 96,61%\n",
    "# KNN works great here, is doing a good work at differentiating a CoverType."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These results can be improved through Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make predictions\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "\n",
    "y_pred_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('KNN (Nearest Neighbors) confusion matrix:')\n",
    "print(metrics.classification_report(y_test, y_pred_knn))\n",
    "print(metrics.confusion_matrix(y_test, y_pred_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these metrics are calculated True Positive, True\n",
    "# Negative, False Positive and False Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision - accuracy of positive prediction\n",
    "# recall - fraction of positives that were correctly identified\n",
    "# f1 score - 2*(Recall*Precision)/(Recall+Precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup a ExtraTreesClassifier classifier\n",
    "etc = ExtraTreesClassifier()\n",
    "# Fit the model\n",
    "etc.fit(X_train, y_train)\n",
    "\n",
    "# Check to see how well our model is performing on the test data\n",
    "accuracy_etc = etc.score(X_test, y_test)*100\n",
    "# Or accuracy_etc= accuracy_score(y_test,y_pred)\n",
    "\n",
    "print('ETC Acurracy: ',accuracy_etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the algorithm managed to hit 92.64% of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make predictions\n",
    "y_pred_etc = etc.predict(X_test)\n",
    "\n",
    "y_pred_etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('DT (ExtraDecisionTrees) confusion matrix:')\n",
    "\n",
    "print(metrics.classification_report(y_test, y_pred_etc))\n",
    "print(metrics.confusion_matrix(y_test, y_pred_etc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter some samples\n",
    "y_test[400:403]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See if the model can predict these 3 samples\n",
    "predictions = etc.predict(X_test[400:403])\n",
    "\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the prediction was correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes - Gaussian Process (GB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GaussianNB()\n",
    "gb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_gb = gb.predict(X_test)\n",
    "accuracy_gb= accuracy_score(y_test,y_pred_gb)*100\n",
    "\n",
    "print('GB Acurracy: ',accuracy_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to improve these results, we will change the size of the test data and the random state\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.10, random_state = 200)\n",
    "gb.fit(X_train,y_train)\n",
    "y_pred_gb = gb.predict(X_test)\n",
    "accuracy_gb= accuracy_score(y_test,y_pred_gb)*100\n",
    "accuracy_gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with 10% for test data, the above statement is verified, where the main advantage of this model is requiring a\n",
    "# small number of training data samples to perform classification efficiently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_pred = gb.predict(X_test)\n",
    "print('NB (GaussianNB) confusion matrix:')\n",
    "print(metrics.classification_report(y_test, y_pred_gb))\n",
    "print(metrics.confusion_matrix(y_test, y_pred_gb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM - Polynomial, Sigmoid and Radial Basis Function Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INC\n",
    "X_train, X_test,y_train, y_test=train_test_split(X,y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_std=sc.transform(X_train)\n",
    "X_test_std=sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Polynomial Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Python degrees function is one of the Python Math functions used to convert the given angle from Radians to Degrees\n",
    "svclassifier = SVC(kernel='poly', degree=8)\n",
    "svclassifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_poly= svclassifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, y_pred_poly))\n",
    "print(classification_report(y_test, y_pred_poly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(y_test) - set(y_pred_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This means that there is no F-score to calculate for this label, and thus\n",
    "# the F-score for this case is considered to be 0.0. Since you requested\n",
    "# an average of the score, you must take into account that a score of 0 was\n",
    "# included in the calculation, and this is why scikit-learn is showing you\n",
    "# that warning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sigmoid Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svclassifier = SVC(kernel='sigmoid')\n",
    "svclassifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_sigmoid = svclassifier.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred_sigmoid))\n",
    "print(classification_report(y_test, y_pred_sigmoid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RBF Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svclassifier = SVC(kernel='rbf')\n",
    "svclassifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rbf = svclassifier.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred_rbf))\n",
    "print(classification_report(y_test, y_pred_rbf))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
