{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anomaly detection in Univariate Time series with Random Forest (Classification), in the context of WISDom project\n",
    "\n",
    "#### Data:\n",
    "    1. Flow Rate Data from a sensor in a Water Sypply System located in Barreiro\n",
    "    2. Holidays since 1970 to 2029 (+ 3 regional holidays of 2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem Definition:\n",
    "The task here is to predict whether or not it is an anomaly.\n",
    "#### Solution:\n",
    "This is a binary classification problem and we will use a random forest classifier to solve this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries and Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime as dt\n",
    "# for graphics\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns; sns.set()\n",
    "# train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "# feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# algorithm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# evaluatuon metrics\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"date\",\"time\",\"flow\",\"anomaly\"]\n",
    "df = pd.read_csv('barreiro_ano.csv', sep=';', names=features)\n",
    "holidays = pd.read_csv('holidays2018.csv',sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New column: DayOfWeek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra column indicating day of week\n",
    "# 0: mon, 1:tue, ..., 5:sat, 6:sun\n",
    "df['dayofweek'] = pd.to_datetime(df['date'],dayfirst=True)\n",
    "df['dayofweek'] = df['dayofweek'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if day is a holiday, then dayofweek is -1\n",
    "df.loc[df.date.isin(holidays.date), 'dayofweek'] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-1 is definitely viable, or is the number 7 better (for example)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date in indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# requisition of Feature Scaling - 1st option\n",
    "# returns the day count from the date\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['date']=df['date'].map(dt.toordinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OR\n",
    "# dt.strftime convert index using specified date_format\n",
    "# Convert date in format d/m/y to date in format y/m/d represented in the column \"int_date\"\n",
    "# df['int_date'] = pd.to_datetime(df['date'],dayfirst=True).dt.strftime(\"%Y%m%d\").astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time in indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract all unique values (time) present in dataframe\n",
    "time_unique_val=df.time.unique()\n",
    "# in order to accept time series with different periods per day\n",
    "periods_per_day=len(time_unique_val)\n",
    "time_unique_ind=np.arange(periods_per_day)\n",
    "#in order to have a mapping between the time of day and its index\n",
    "time_unique=pd.DataFrame({'time':time_unique_val, 'time_unique_ind':time_unique_ind})\n",
    "#creates a column with the time index\n",
    "df['time'] = df['time'].map(time_unique.set_index('time')['time_unique_ind'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>flow</th>\n",
       "      <th>anomaly</th>\n",
       "      <th>dayofweek</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>736695</td>\n",
       "      <td>0</td>\n",
       "      <td>18.333067</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>736695</td>\n",
       "      <td>1</td>\n",
       "      <td>18.333067</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>736695</td>\n",
       "      <td>2</td>\n",
       "      <td>19.784872</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>736695</td>\n",
       "      <td>3</td>\n",
       "      <td>22.294744</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>736695</td>\n",
       "      <td>4</td>\n",
       "      <td>27.229756</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35035</th>\n",
       "      <td>737059</td>\n",
       "      <td>91</td>\n",
       "      <td>24.792000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35036</th>\n",
       "      <td>737059</td>\n",
       "      <td>92</td>\n",
       "      <td>23.029933</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35037</th>\n",
       "      <td>737059</td>\n",
       "      <td>93</td>\n",
       "      <td>20.415628</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35038</th>\n",
       "      <td>737059</td>\n",
       "      <td>94</td>\n",
       "      <td>22.019056</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35039</th>\n",
       "      <td>737059</td>\n",
       "      <td>95</td>\n",
       "      <td>20.792000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35040 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  time       flow  anomaly  dayofweek\n",
       "0      736695     0  18.333067        0         -1\n",
       "1      736695     1  18.333067        0         -1\n",
       "2      736695     2  19.784872        0         -1\n",
       "3      736695     3  22.294744        0         -1\n",
       "4      736695     4  27.229756        0         -1\n",
       "...       ...   ...        ...      ...        ...\n",
       "35035  737059    91  24.792000        0          0\n",
       "35036  737059    92  23.029933        0          0\n",
       "35037  737059    93  20.415628        0          0\n",
       "35038  737059    94  22.019056        0          0\n",
       "35039  737059    95  20.792000        0          0\n",
       "\n",
       "[35040 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, [0,1,2,4]].values\n",
    "y = df.iloc[:, 3].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.36695000e+05,  0.00000000e+00,  1.83330667e+01,\n",
       "        -1.00000000e+00],\n",
       "       [ 7.36695000e+05,  1.00000000e+00,  1.83330667e+01,\n",
       "        -1.00000000e+00],\n",
       "       [ 7.36695000e+05,  2.00000000e+00,  1.97848722e+01,\n",
       "        -1.00000000e+00],\n",
       "       ...,\n",
       "       [ 7.37059000e+05,  9.30000000e+01,  2.04156278e+01,\n",
       "         0.00000000e+00],\n",
       "       [ 7.37059000e+05,  9.40000000e+01,  2.20190556e+01,\n",
       "         0.00000000e+00],\n",
       "       [ 7.37059000e+05,  9.50000000e+01,  2.07920000e+01,\n",
       "         0.00000000e+00]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Therefore, it would be beneficial to scale our data (this step isn't as important for the random forests algorithm)\n",
    "# To do so, we will use Scikit-Learn's StandardScaler class.\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.28889222, -1.46179811, -0.98349514, -1.3211612 ],\n",
       "       [ 0.12747893,  0.59551838,  0.69261188,  1.49837869],\n",
       "       [ 0.36485141,  1.64222327,  0.10842009,  1.02845538],\n",
       "       ...,\n",
       "       [ 1.27636173,  0.7037982 , -0.54338321, -0.85123789],\n",
       "       [ 0.93454536, -0.73993267,  0.48422766,  0.55853206],\n",
       "       [-1.45816923, -0.12634705, -0.40093037, -1.3211612 ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.23029165,  0.84817129,  0.44078602,  0.08860875],\n",
       "       [ 1.73211689,  1.71440981, -0.73806517, -1.3211612 ],\n",
       "       [ 0.4882851 ,  0.01802603,  2.11318655, -0.38131457],\n",
       "       ...,\n",
       "       [-0.59413341, -0.59555959, -0.09367211, -1.3211612 ],\n",
       "       [-0.41373032, -1.06477212, -1.23308912,  1.02845538],\n",
       "       [-0.87898038, -1.35351829, -1.34629055,  1.02845538]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier(n_estimators=550) # random_state=0\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For classification problems the metrics used to evaluate an algorithm are accuracy, confusion matrix, precision recall, and F1 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10489     0]\n",
      " [    5    18]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     10489\n",
      "           1       1.00      0.78      0.88        23\n",
      "\n",
      "    accuracy                           1.00     10512\n",
      "   macro avg       1.00      0.89      0.94     10512\n",
      "weighted avg       1.00      1.00      1.00     10512\n",
      "\n",
      "0.9995243531202436\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy achieved for by our random forest classifier with 550 trees is 99.95%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
